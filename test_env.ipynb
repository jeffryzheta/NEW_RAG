{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from operator import itemgetter\n",
    "from config_env import embedding_endpoint, llm_endpoint, AZURE_OPENAI_VERSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models and vector store\n",
    "api_key = 'd7fd42addeff4f4a91f9beea8996f4cc'  # Replace with your actual API key\n",
    "\n",
    "embedding_model = AzureOpenAIEmbeddings(azure_endpoint=embedding_endpoint, api_key=api_key)\n",
    "vector_store = InMemoryVectorStore(embedding_model).load('vector_store_v1', embedding_model)\n",
    "open_ai_llm = AzureChatOpenAI(\n",
    "    openai_api_version=AZURE_OPENAI_VERSION,\n",
    "    azure_endpoint=llm_endpoint,\n",
    "    temperature=0,\n",
    "    api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Instructions: You are a customer service assistant chatbot at Bank Mandiri known as Mita. Your main role is to assist customers by providing accurate information, answering questions, and resolving issues related to our products and services. \n",
    "Always use bahasa indonesia in response.\n",
    "You are an assistant for answering specific questions related to Bank Mandiri.\n",
    "If a question is outside the topic of Bank Mandiri and our products or services, kindly state that the question is not relevant. If a user simply wants to try the service or asks who you are, introduce yourself and ask how you can assist them. \n",
    "Reformat your answers to be more straigtforward\n",
    "Main Guidelines:\n",
    "1. Polite and Professional Tone: Always communicate in a friendly and professional manner.\n",
    "2. Empathy and Understanding: Acknowledge customer concerns and express understanding.\n",
    "3. Clarity and Accuracy: Provide clear, concise, and accurate information.\n",
    "4. Focus on Problem Resolution: Strive to resolve issues efficiently and effectively.\n",
    "5. Escalation Protocol: If a customer's issue cannot be resolved, inform them that their question will be escalated to a human representative.\n",
    "                                                   \n",
    "You are designed to learn from interactions, so continuously improve your responses based on customer feedback.\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hypothetical_rag_chain(vectorstore):\n",
    "    def retrieve_docs(query: str) -> str:\n",
    "        docs = vectorstore.similarity_search(query, k=3)\n",
    "        return summarize_content(\"\\n\\n\".join(doc.page_content for doc in docs))\n",
    "\n",
    "    retriever = RunnableLambda(retrieve_docs)\n",
    "\n",
    "    chain = (\n",
    "        {\n",
    "            \"question\": itemgetter(\"original_question\"),\n",
    "            \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
    "        }\n",
    "        | response_prompt\n",
    "        | open_ai_llm\n",
    "    )\n",
    "    \n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_content(content):\n",
    "    summary_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Instruction: \"gabungkan semua informasi yang didapat dan kelompokkan\n",
    "    tampilkan informasi paling relevan\" \n",
    "    {content}\n",
    "    \"\"\")\n",
    "    \n",
    "    summary_chain = summary_prompt | open_ai_llm\n",
    "    summary_response = summary_chain.invoke({\"content\": content})\n",
    "    return summary_response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSES = {\n",
    "    'id': {\n",
    "        'greeting': \"ðŸ‘‹ Hai! Saya Mita, asisten layanan pelanggan Bank Mandiri. Untuk memberikan pelayanan terbaik silahkan bertanya atau beri saya instruksi\",\n",
    "        'short_greeting': \"ðŸ‘‹ Hai! Saya Mita, asisten layanan pelanggan Bank Mandiri.\",\n",
    "        'language_prompt': \"Untuk memberikan pelayanan terbaik, apakah Anda lebih nyaman menggunakan Bahasa Indonesia atau English?\",\n",
    "        'irrelevant': \"Maaf, pertanyaan tersebut tidak relevan dengan produk atau layanan Bank Mandiri. Silakan ajukan pertanyaan lain seputar layanan kami!\",\n",
    "        'error': \"Maaf, terjadi kesalahan dalam memproses permintaan Anda. Silakan coba lagi.\",\n",
    "        'clarification': \"Mohon maaf, saya kurang memahami maksud Anda. Bisakah Anda menjelaskan lebih detail?\",\n",
    "    },\n",
    "    'en': {\n",
    "        'greeting': \"ðŸ‘‹ Hi! I'm Mita, Bank Mandiri's customer service assistant. To provide the best service, please give me instruction or ask anything\",\n",
    "        'short_greeting': \"ðŸ‘‹ Hi! I'm Mita, Bank Mandiri's customer service assistant.\",\n",
    "        'language_prompt': \"To provide the best service, would you prefer to communicate in Bahasa Indonesia or English?\",\n",
    "        'irrelevant': \"I apologize, but that question isn't relevant to Bank Mandiri's products or services. Please feel free to ask about our services!\",\n",
    "        'error': \"I apologize, but there was an error processing your request. Please try again.\",\n",
    "        'clarification': \"I'm sorry, I didn't quite understand. Could you please elaborate?\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language_preference(text):\n",
    "    \"\"\"Simple language detection based on common words\"\"\"\n",
    "    # For simplicity, we're always returning 'id' here. In a real implementation,\n",
    "    # you'd want to implement actual language detection logic.\n",
    "    return 'id'\n",
    "\n",
    "def get_response(key, lang='id'):\n",
    "    \"\"\"Get response in the specified language\"\"\"\n",
    "    return RESPONSES[lang][key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 20:33:43.111 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-09 20:33:49.792 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-09 20:33:49.793 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-09 20:33:49.794 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-09 20:33:49.850 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-09 20:33:49.850 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-09 20:33:49.851 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-09 20:33:49.852 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-09 20:33:49.854 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-09 20:33:49.855 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-09 20:33:49.856 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-09 20:33:49.856 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from operator import itemgetter\n",
    "from config_env import embedding_endpoint, llm_endpoint, AZURE_OPENAI_VERSION\n",
    "\n",
    "st.set_page_config(page_title=\"Hypothetical RAG Chatbot\", layout=\"wide\")\n",
    "\n",
    "# Initialize models and vector store\n",
    "api_key = 'd7fd42addeff4f4a91f9beea8996f4cc'  # Replace with your actual API key\n",
    "\n",
    "embedding_model = AzureOpenAIEmbeddings(azure_endpoint=embedding_endpoint, api_key=api_key)\n",
    "vector_store = InMemoryVectorStore(embedding_model).load('vector_store_v1', embedding_model)\n",
    "open_ai_llm = AzureChatOpenAI(\n",
    "    openai_api_version=AZURE_OPENAI_VERSION,\n",
    "    azure_endpoint=llm_endpoint,\n",
    "    temperature=0,\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "# Chat prompt template\n",
    "response_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Instructions: You are a customer service assistant chatbot at Bank Mandiri known as Mita. Your main role is to assist customers by providing accurate information, answering questions, and resolving issues related to our products and services. \n",
    "Always use bahasa indonesia in response.\n",
    "You are an assistant for answering specific questions related to Bank Mandiri.\n",
    "If a question is outside the topic of Bank Mandiri and our products or services, kindly state that the question is not relevant. If a user simply wants to try the service or asks who you are, introduce yourself and ask how you can assist them. \n",
    "Reformat your answers to be more straigtforward\n",
    "Main Guidelines:\n",
    "1. Polite and Professional Tone: Always communicate in a friendly and professional manner.\n",
    "2. Empathy and Understanding: Acknowledge customer concerns and express understanding.\n",
    "3. Clarity and Accuracy: Provide clear, concise, and accurate information.\n",
    "4. Focus on Problem Resolution: Strive to resolve issues efficiently and effectively.\n",
    "5. Escalation Protocol: If a customer's issue cannot be resolved, inform them that their question will be escalated to a human representative.\n",
    "                                                   \n",
    "You are designed to learn from interactions, so continuously improve your responses based on customer feedback.\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def create_hypothetical_rag_chain(vectorstore):\n",
    "    def retrieve_docs(query: str) -> str:\n",
    "        docs = vectorstore.similarity_search(query, k=3)\n",
    "        return summarize_content(\"\\n\\n\".join(doc.page_content for doc in docs))\n",
    "\n",
    "    retriever = RunnableLambda(retrieve_docs)\n",
    "\n",
    "    chain = (\n",
    "        {\n",
    "            \"question\": itemgetter(\"original_question\"),\n",
    "            \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
    "        }\n",
    "        | response_prompt\n",
    "        | open_ai_llm\n",
    "    )\n",
    "    \n",
    "    return chain\n",
    "\n",
    "def summarize_content(content):\n",
    "    summary_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Instruction: \"gabungkan semua informasi yang didapat dan kelompokkan\n",
    "    tampilkan informasi paling relevan\" \n",
    "    {content}\n",
    "    \"\"\")\n",
    "    \n",
    "    summary_chain = summary_prompt | open_ai_llm\n",
    "    summary_response = summary_chain.invoke({\"content\": content})\n",
    "    return summary_response.content\n",
    "\n",
    "# Predefined responses\n",
    "RESPONSES = {\n",
    "    'id': {\n",
    "        'greeting': \"ðŸ‘‹ Hai! Saya Mita, asisten layanan pelanggan Bank Mandiri. Untuk memberikan pelayanan terbaik silahkan bertanya atau beri saya instruksi\",\n",
    "        'short_greeting': \"ðŸ‘‹ Hai! Saya Mita, asisten layanan pelanggan Bank Mandiri.\",\n",
    "        'language_prompt': \"Untuk memberikan pelayanan terbaik, apakah Anda lebih nyaman menggunakan Bahasa Indonesia atau English?\",\n",
    "        'irrelevant': \"Maaf, pertanyaan tersebut tidak relevan dengan produk atau layanan Bank Mandiri. Silakan ajukan pertanyaan lain seputar layanan kami!\",\n",
    "        'error': \"Maaf, terjadi kesalahan dalam memproses permintaan Anda. Silakan coba lagi.\",\n",
    "        'clarification': \"Mohon maaf, saya kurang memahami maksud Anda. Bisakah Anda menjelaskan lebih detail?\",\n",
    "    },\n",
    "    'en': {\n",
    "        'greeting': \"ðŸ‘‹ Hi! I'm Mita, Bank Mandiri's customer service assistant. To provide the best service, please give me instruction or ask anything\",\n",
    "        'short_greeting': \"ðŸ‘‹ Hi! I'm Mita, Bank Mandiri's customer service assistant.\",\n",
    "        'language_prompt': \"To provide the best service, would you prefer to communicate in Bahasa Indonesia or English?\",\n",
    "        'irrelevant': \"I apologize, but that question isn't relevant to Bank Mandiri's products or services. Please feel free to ask about our services!\",\n",
    "        'error': \"I apologize, but there was an error processing your request. Please try again.\",\n",
    "        'clarification': \"I'm sorry, I didn't quite understand. Could you please elaborate?\",\n",
    "    }\n",
    "}\n",
    "\n",
    "def detect_language_preference(text):\n",
    "    \"\"\"Simple language detection based on common words\"\"\"\n",
    "    # For simplicity, we're always returning 'id' here. In a real implementation,\n",
    "    # you'd want to implement actual language detection logic.\n",
    "    return 'id'\n",
    "\n",
    "def get_response(key, lang='id'):\n",
    "    \"\"\"Get response in the specified language\"\"\"\n",
    "    return RESPONSES[lang][key]\n",
    "\n",
    "# Initialize session state\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "if \"language_set\" not in st.session_state:\n",
    "    st.session_state.language_set = False\n",
    "if \"selected_language\" not in st.session_state:\n",
    "    st.session_state.selected_language = None\n",
    "\n",
    "# Initialize the RAG chain\n",
    "rag_chain = create_hypothetical_rag_chain(vector_store)\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"Your Truly Livin Partner\")\n",
    "\n",
    "# Display chat history\n",
    "for msg in st.session_state.messages:\n",
    "    with st.chat_message(msg[\"role\"]):\n",
    "        st.markdown(msg[\"content\"])\n",
    "\n",
    "# User input handling\n",
    "if prompt := st.chat_input(\"What would you like to know?\"):\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(prompt)\n",
    "\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"Thinking...\"):\n",
    "            try:\n",
    "                if not st.session_state.language_set:\n",
    "                    st.session_state.selected_language = detect_language_preference(prompt)\n",
    "                    st.session_state.language_set = True\n",
    "                \n",
    "                lang = st.session_state.selected_language\n",
    "                \n",
    "                response = rag_chain.invoke({\n",
    "                    \"question\": prompt,\n",
    "                    \"original_question\": prompt\n",
    "                })\n",
    "\n",
    "                full_response = response.content\n",
    "\n",
    "                if \"tidak relevan\" in full_response.lower() or \"not relevant\" in full_response.lower():\n",
    "                    st.markdown(get_response('irrelevant', lang))\n",
    "                else:\n",
    "                    st.markdown(full_response)\n",
    "\n",
    "                st.session_state.messages.append({\n",
    "                    \"role\": \"assistant\", \n",
    "                    \"content\": full_response\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                st.error(get_response('error', lang))\n",
    "                print(f\"Error: {str(e)}\")  # For debugging"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
